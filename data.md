'''
P0: 0.888859 (0.036467)
P1: 0.667391 (0.077321)
P2: 0.664402 (0.084189)
P3: 0.639674 (0.080567)
P4: 0.547283 (0.067172)
P5: 0.608424 (0.021065)
P6: 0.608424 (0.021065)
P7: 0.608424 (0.021065)
P8: 0.888859 (0.036467)
P9: 0.907880 (0.019385)
P10: 0.871739 (0.051398)
P11: 0.837228 (0.086330)
P12: 0.669293 (0.123473)
P13: 0.672283 (0.083492)
P14: 0.561413 (0.054797)
P15: 0.543750 (0.101417)
Best model is:
Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,
      max_iter=5000, n_iter=None, n_jobs=1, penalty='l1', random_state=0,
      shuffle=True, tol=None, verbose=0, warm_start=False)
With an accuracy score of: 0.8805646036916395
Took 5000 iterations
[[538  11]
 [ 99 273]]
             precision    recall  f1-score   support

        0.0       0.84      0.98      0.91       549
        1.0       0.96      0.73      0.83       372

avg / total       0.89      0.88      0.88       921
'''